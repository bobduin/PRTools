<html><body bgcolor="#3030a0"><table bgcolor="#eeeeee"  border="5" cellspacing="0" cellpadding="5" width="700" white-space="normal"  align="center"><tr><td><table border="0" cellspacing="0" cellpadding="3" width="100%" align="center"><tr><td><a href="../prtools.html">PRTools Contents</a></td><td><p align="right"><a href="http://37steps.com/prtools/" target="_top">PRTools User Guide</a></p></td></tr></table><head><title>rnnc</title></head>
<p align="center"><font face="Courier" size=5><strong>RNNC</strong></font></p>
<h3> Random Neural Net classifier
</h3>
<p>
</p>
<p><font face="Courier" size="2">&nbsp;&nbsp;&nbsp;&nbsp;W = RNNC(A,N,S)</font><br>
</p>
<p></p><p>
<table cellspacing="0" cellpadding="3" width="100%" align="center" border="0"<tr> <td width="100"><font size="4"><strong>Input</strong></font></td><tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;A</font></td><td valign="baseline"><font face="Courier" size="2">    </font>Input dataset<tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;N</font></td><td valign="baseline"><font face="Courier" size="2">    </font>Number of neurons in the hidden layer<tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;S</font></td><td valign="baseline"><font face="Courier" size="2">    </font>Standard deviation of weights in an input layer (default:<font face="Courier" size="2"> 1) </font></td></tr></table>
</p><p><table cellspacing="0" cellpadding="3" width="100%" align="center" border="0"<tr> <td width="120"><font size="4"><strong>Output</strong></font></td><tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;W</font></td><td valign="baseline"><font face="Courier" size="2">    </font>Trained Random Neural Net classifier</td></tr></table>
</p><h3> Description</h3><p><font face="Courier" size="2"> W </font>is a feed-forward neural net with one hidden layer of<font face="Courier" size="2"> N </font>sigmoid neurons.&nbsp; The input layer rescales the input features to unit variance; the hidden&nbsp; layer has normally distributed weights and biases with zero mean and&nbsp; standard deviation<font face="Courier" size="2"> S</font>. The output layer is trained by the dataset<font face="Courier" size="2"> A</font>.&nbsp; Default<font face="Courier" size="2"> N </font>is number of objects<font face="Courier" size="2"> * 0.2</font>, but not more than<font face="Courier" size="2"> 100</font>.</p>
<p> If<font face="Courier" size="2"> N </font>and/or<font face="Courier" size="2"> S </font>is <font face="Courier" size="2">NaN</font> they are optimised by<font face="Courier" size="2"> REGOPTC</font>.</p>
<p> Uses the Mathworks' Neural Network toolbox.</p><h3> Reference(s)</h3><p>1. W.F. Schmidt, M.A. Kraaijveld, and R.P.W. Duin, Feed forward neural&nbsp;networks with random weights, Proc. ICPR11, Volume II, 1992, 1-4.<br>2. G.B. Huang, Q.Y. Zhu, C.K. Siew, Extreme learning machine: theory and&nbsp;applications, Neurocomputing, 70 (1), 2006, 489-501</p><h3> See also</h3><p>
<font face="Courier" size="3"><a href="../prtools/mappings.html">mappings</a>, <a href="../prtools/datasets.html">datasets</a>, <a href="../prtools/lmnc.html">lmnc</a>, <a href="../prtools/bpxnc.html">bpxnc</a>, <a href="../prtools/neurc.html">neurc</a>, <a href="../prtools/rbnc.html">rbnc</a>, </font></p><table border="0" cellspacing="0" cellpadding="3" width="100%" align="center"><tr><td><a href="../prtools.html">PRTools Contents</a></td><td><p align="right"><a href="http://37steps.com/prtools/" target="_top">PRTools User Guide</a></p></td></tr></table><table border="0" cellspacing="0" cellpadding="3" width="100%"><tr><td align="center"><em>This file has been automatically generated. If badly readable, use the help-command in Matlab.</em></td></tr></table></table></body></html>