<html><body bgcolor="#3030a0"><table bgcolor="#eeeeee"  border="5" cellspacing="0" cellpadding="5" width="700" white-space="normal"  align="center"><tr><td><table border="0" cellspacing="0" cellpadding="3" width="100%" align="center"><tr><td><a href="../prtools.html">PRTools Contents</a></td><td><p align="right"><a href="http://37steps.com/prtools/" target="_top">PRTools User Guide</a></p></td></tr></table><head><title>nusvc</title></head>
<p align="center"><font face="Courier" size=5><strong>NUSVC</strong></font></p>
<h3> Trainable classifier: Support Vector Machine, nu-algorithme
</h3>
<p>
</p>
<p><font face="Courier" size="2">&nbsp;&nbsp;&nbsp;&nbsp;[W,J,NU] = NUSVC(A,KERNEL,NU)</font><br>
<font face="Courier" size="2">&nbsp;&nbsp;&nbsp;&nbsp;[W,J,NU] = A*NUSVC([],KERNEL,NU)</font><br>
<font face="Courier" size="2">&nbsp;&nbsp;&nbsp;&nbsp;[W,J,NU] = A*NUSVC(KERNEL,NU)</font><br>
</p>
<p></p><p>
<table cellspacing="0" cellpadding="3" width="100%" align="center" border="0"<tr> <td width="100"><font size="4"><strong>Input</strong></font></td><tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;A</font></td><td valign="baseline"><font face="Courier" size="2">         </font>Dataset<tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;KERNEL</font></td><td valign="baseline"> Untrained mapping to compute kernel by<font face="Courier" size="2"> A*(A*KERNEL) </font>during&nbsp; training, or<font face="Courier" size="2"> B*(A*KERNEL) </font>during testing with dataset<font face="Courier" size="2"> B</font>.<br>-&nbsp;  String to compute kernel matrices by<font face="Courier" size="2"> FEVAL(KERNEL,B,A) </font> Default: linear kernel<font face="Courier" size="2"> (PROXM([]</font>,'p'<font face="Courier" size="2">,1)); </font><tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;NU</font></td><td valign="baseline"><font face="Courier" size="2">       </font>Regularisation parameter<font face="Courier" size="2"> (0 < NU < 1): </font>expected fraction of<font face="Courier" size="2"> SV </font> (optional; default: max(leave-one-out<font face="Courier" size="2"> 1_NN </font>error<font face="Courier" size="2">,0.01)) </font></td></tr></table>
</p><p><table cellspacing="0" cellpadding="3" width="100%" align="center" border="0"<tr> <td width="120"><font size="4"><strong>Output</strong></font></td><tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;W</font></td><td valign="baseline"><font face="Courier" size="2">        </font>Mapping: Support Vector Classifier<tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;J</font></td><td valign="baseline"><font face="Courier" size="2">        </font>Object indices of support objects<tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;NU</font></td><td valign="baseline"><font face="Courier" size="2">       </font>Actual nu_value used</td></tr></table>
</p><h3> Description</h3><p> Optimises a support vector classifier for the dataset<font face="Courier" size="2"> A </font>by quadratic&nbsp; programming. The difference with the standard<font face="Courier" size="2"> SVC </font>routine is the use and&nbsp; interpretation of the regularisation parameter<font face="Courier" size="2"> NU</font>. It is an upperbound&nbsp; for the expected classification error. By default<font face="Courier" size="2"> NU </font>is estimated by the&nbsp; leave-one-error of the<font face="Courier" size="2"> 1_NN </font>rule. For<font face="Courier" size="2"> NU = </font><font face="Courier" size="2">NaN</font> an automatic optimisation&nbsp; is performed using<font face="Courier" size="2"> REGOPTC</font>.</p>
<p> If<font face="Courier" size="2"> KERNEL = 0 </font>it is assumed that<font face="Courier" size="2"> A </font>is already the kernelmatrix (square).&nbsp; In this case also a kernel matrix<font face="Courier" size="2"> B </font>should be supplied at evaluation by&nbsp;<font face="Courier" size="2"> B*W </font>or<font face="Courier" size="2"> PRMAP(B,W)</font>.</p>
<p> There are several ways to define<font face="Courier" size="2"> KERNEL</font>, e.g.<font face="Courier" size="2"> PROXM([]</font>,'r'<font face="Courier" size="2">,1) </font>for a&nbsp; radial basis kernel or by<font face="Courier" size="2"> USERKERNEL </font>for a user defined kernel.</p>
<p><font face="Courier" size="2"> SVC </font>is basically a two-class classifier. Multi-class problems are solved&nbsp; in a one-against-rest fashion by<font face="Courier" size="2"> MCLASSC</font>. The resulting base-classifiers&nbsp; are combined by the maximum confidence rule. A better, non-linear&nbsp; combiner might be<font face="Courier" size="2"> QDC</font>, e.g.<font face="Courier" size="2"> W = A*(SVC*QDC([],[]</font>,1e-6))</p><h3> See also</h3><p>
<font face="Courier" size="3"><a href="../prtools/mappings.html">mappings</a>, <a href="../prtools/datasets.html">datasets</a>, <a href="../prtools/svc.html">svc</a>, <a href="../prtools/nusvo.html">nusvo</a>, <a href="../prtools/proxm.html">proxm</a>, <a href="../prtools/userkernel.html">userkernel</a>, <a href="../prtools/regoptc.html">regoptc</a>, <a href="../prtools/mclassc.html">mclassc</a>, <a href="../prtools/qdc.html">qdc</a>, </font></p><table border="0" cellspacing="0" cellpadding="3" width="100%" align="center"><tr><td><a href="../prtools.html">PRTools Contents</a></td><td><p align="right"><a href="http://37steps.com/prtools/" target="_top">PRTools User Guide</a></p></td></tr></table><table border="0" cellspacing="0" cellpadding="3" width="100%"><tr><td align="center"><em>This file has been automatically generated. If badly readable, use the help-command in Matlab.</em></td></tr></table></table></body></html>