<html><body bgcolor="#3030a0"><table bgcolor="#eeeeee"  border="5" cellspacing="0" cellpadding="5" width="700" white-space="normal"  align="center"><tr><td><table border="0" cellspacing="0" cellpadding="3" width="100%" align="center"><tr><td><a href="../prtools.html">PRTools Contents</a></td><td><p align="right"><a href="http://37steps.com/prtools/" target="_top">PRTools User Guide</a></p></td></tr></table><head><title>klldc</title></head>
<p align="center"><font face="Courier" size=5><strong>KLLDC</strong></font></p>
<h3> Linear classifier built on the KL expansion of the common covariance matrix
</h3>
<p>
</p>
<p><font face="Courier" size="2">&nbsp;&nbsp;&nbsp;W = KLLDC(A,N)</font><br>
<font face="Courier" size="2">&nbsp;&nbsp;&nbsp;W = KLLDC(A,ALF)</font><br>
</p>
<p></p><p>
<table cellspacing="0" cellpadding="3" width="100%" align="center" border="0"<tr> <td width="100"><font size="4"><strong>Input</strong></font></td><tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;A</font></td><td valign="baseline"><font face="Courier" size="2">     </font>Dataset<tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;N</font></td><td valign="baseline"><font face="Courier" size="2">     </font>Number of significant eigenvectors<tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;ALF</font></td><td valign="baseline"><font face="Courier" size="2">   0 < ALF <= 1</font>, percentage of the total variance explained (default:<font face="Courier" size="2"> 0.9) </font></td></tr></table>
</p><p><table cellspacing="0" cellpadding="3" width="100%" align="center" border="0"<tr> <td width="120"><font size="4"><strong>Output</strong></font></td><tr> <td width="120" valign="baseline"><font face="Courier" size="2">&nbsp;W</font></td><td valign="baseline"><font face="Courier" size="2">     </font>Linear classifier</td></tr></table>
</p><h3> Description</h3><p> Finds the linear discriminant function<font face="Courier" size="2"> W </font>for the dataset<font face="Courier" size="2"> A</font>. This is done&nbsp; by computing the<font face="Courier" size="2"> LDC </font>on the data projected on the first eigenvectors of&nbsp; the averaged covariance matrix of the classes. Either first<font face="Courier" size="2"> N </font>eigenvectors&nbsp; are used or the number of eigenvectors is determined such that<font face="Courier" size="2"> ALF</font>, the&nbsp; percentage of the total variance is explained. (Karhunen Loeve expansion)</p>
<p> If<font face="Courier" size="2"> N (ALF) </font>is <font face="Courier" size="2">NaN</font> it is optimised by<font face="Courier" size="2"> REGOPTC</font>.</p><h3> See also</h3><p>
<font face="Courier" size="3"><a href="../prtools/mappings.html">mappings</a>, <a href="../prtools/datasets.html">datasets</a>, <a href="../prtools/pcldc.html">pcldc</a>, <a href="../prtools/klm.html">klm</a>, <a href="../prtools/fisherm.html">fisherm</a>, <a href="../prtools/regoptc.html">regoptc</a>, </font></p><table border="0" cellspacing="0" cellpadding="3" width="100%" align="center"><tr><td><a href="../prtools.html">PRTools Contents</a></td><td><p align="right"><a href="http://37steps.com/prtools/" target="_top">PRTools User Guide</a></p></td></tr></table><table border="0" cellspacing="0" cellpadding="3" width="100%"><tr><td align="center"><em>This file has been automatically generated. If badly readable, use the help-command in Matlab.</em></td></tr></table></table></body></html>